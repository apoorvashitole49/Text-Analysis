{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\apoor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\apoor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>CONAME</th>\n",
       "      <th>FYRMO</th>\n",
       "      <th>FDATE</th>\n",
       "      <th>FORM</th>\n",
       "      <th>SECFNAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199803</td>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>10-K405</td>\n",
       "      <td>edgar/data/3662/0000950170-98-000413.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199805</td>\n",
       "      <td>1998-05-15</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-001001.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199808</td>\n",
       "      <td>1998-08-13</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-000783.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-12</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002145.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-16</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-001203.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CIK            CONAME   FYRMO      FDATE     FORM  \\\n",
       "0  3662  SUNBEAM CORP/FL/  199803 1998-03-06  10-K405   \n",
       "1  3662  SUNBEAM CORP/FL/  199805 1998-05-15     10-Q   \n",
       "2  3662  SUNBEAM CORP/FL/  199808 1998-08-13  NT 10-Q   \n",
       "3  3662  SUNBEAM CORP/FL/  199811 1998-11-12   10-K/A   \n",
       "4  3662  SUNBEAM CORP/FL/  199811 1998-11-16  NT 10-Q   \n",
       "\n",
       "                                   SECFNAME  \n",
       "0  edgar/data/3662/0000950170-98-000413.txt  \n",
       "1  edgar/data/3662/0000950170-98-001001.txt  \n",
       "2  edgar/data/3662/0000950172-98-000783.txt  \n",
       "3  edgar/data/3662/0000950170-98-002145.txt  \n",
       "4  edgar/data/3662/0000950172-98-001203.txt  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('C:\\\\Users\\\\apoor\\\\Downloads\\\\cik_list.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 'https://www.sec.gov/Archives/'\n",
    "links = [y+x for x in df['SECFNAME']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading reports...\n",
      "Total 1 reports saved\n",
      "Total 2 reports saved\n",
      "Total 3 reports saved\n",
      "Total 4 reports saved\n",
      "Total 5 reports saved\n",
      "Total 6 reports saved\n",
      "Total 7 reports saved\n",
      "Total 8 reports saved\n",
      "Total 9 reports saved\n",
      "Total 10 reports saved\n",
      "Total 11 reports saved\n",
      "Total 12 reports saved\n",
      "Total 13 reports saved\n",
      "Total 14 reports saved\n",
      "Total 15 reports saved\n",
      "Total 16 reports saved\n",
      "Total 17 reports saved\n",
      "Total 18 reports saved\n",
      "Total 19 reports saved\n",
      "Total 20 reports saved\n",
      "Total 21 reports saved\n",
      "Total 22 reports saved\n",
      "Total 23 reports saved\n",
      "Total 24 reports saved\n",
      "Total 25 reports saved\n",
      "Total 26 reports saved\n",
      "Total 27 reports saved\n",
      "Total 28 reports saved\n",
      "Total 29 reports saved\n",
      "Total 30 reports saved\n",
      "Total 31 reports saved\n",
      "Total 32 reports saved\n",
      "Total 33 reports saved\n",
      "Total 34 reports saved\n",
      "Total 35 reports saved\n",
      "Total 36 reports saved\n",
      "Total 37 reports saved\n",
      "Total 38 reports saved\n",
      "Total 39 reports saved\n",
      "Total 40 reports saved\n",
      "Total 41 reports saved\n",
      "Total 42 reports saved\n",
      "Total 43 reports saved\n",
      "Total 44 reports saved\n",
      "Total 45 reports saved\n",
      "Total 46 reports saved\n",
      "Total 47 reports saved\n",
      "Total 48 reports saved\n",
      "Total 49 reports saved\n",
      "Total 50 reports saved\n",
      "Total 51 reports saved\n",
      "Total 52 reports saved\n",
      "Total 53 reports saved\n",
      "Total 54 reports saved\n",
      "Total 55 reports saved\n",
      "Total 56 reports saved\n",
      "Total 57 reports saved\n",
      "Total 58 reports saved\n",
      "Total 59 reports saved\n",
      "Total 60 reports saved\n",
      "Total 61 reports saved\n",
      "Total 62 reports saved\n",
      "Total 63 reports saved\n",
      "Total 64 reports saved\n",
      "Total 65 reports saved\n",
      "Total 66 reports saved\n",
      "Total 67 reports saved\n",
      "Total 68 reports saved\n",
      "Total 69 reports saved\n",
      "Total 70 reports saved\n",
      "Total 71 reports saved\n",
      "Total 72 reports saved\n",
      "Total 73 reports saved\n",
      "Total 74 reports saved\n",
      "Total 75 reports saved\n",
      "Total 76 reports saved\n",
      "Total 77 reports saved\n",
      "Total 78 reports saved\n",
      "Total 79 reports saved\n",
      "Total 80 reports saved\n",
      "Total 81 reports saved\n",
      "Total 82 reports saved\n",
      "Total 83 reports saved\n",
      "Total 84 reports saved\n",
      "Total 85 reports saved\n",
      "Total 86 reports saved\n",
      "Total 87 reports saved\n",
      "Total 88 reports saved\n",
      "Total 89 reports saved\n",
      "Total 90 reports saved\n",
      "Total 91 reports saved\n",
      "Total 92 reports saved\n",
      "Total 93 reports saved\n",
      "Total 94 reports saved\n",
      "Total 95 reports saved\n",
      "Total 96 reports saved\n",
      "Total 97 reports saved\n",
      "Total 98 reports saved\n",
      "Total 99 reports saved\n",
      "Total 100 reports saved\n",
      "Total 101 reports saved\n",
      "Total 102 reports saved\n",
      "Total 103 reports saved\n",
      "Total 104 reports saved\n",
      "Total 105 reports saved\n",
      "Total 106 reports saved\n",
      "Total 107 reports saved\n",
      "Total 108 reports saved\n",
      "Total 109 reports saved\n",
      "Total 110 reports saved\n",
      "Total 111 reports saved\n",
      "Total 112 reports saved\n",
      "Total 113 reports saved\n",
      "Total 114 reports saved\n",
      "Total 115 reports saved\n",
      "Total 116 reports saved\n",
      "Total 117 reports saved\n",
      "Total 118 reports saved\n",
      "Total 119 reports saved\n",
      "Total 120 reports saved\n",
      "Total 121 reports saved\n",
      "Total 122 reports saved\n",
      "Total 123 reports saved\n",
      "Total 124 reports saved\n",
      "Total 125 reports saved\n",
      "Total 126 reports saved\n",
      "Total 127 reports saved\n",
      "Total 128 reports saved\n",
      "Total 129 reports saved\n",
      "Total 130 reports saved\n",
      "Total 131 reports saved\n",
      "Total 132 reports saved\n",
      "Total 133 reports saved\n",
      "Total 134 reports saved\n",
      "Total 135 reports saved\n",
      "Total 136 reports saved\n",
      "Total 137 reports saved\n",
      "Total 138 reports saved\n",
      "Total 139 reports saved\n",
      "Total 140 reports saved\n",
      "Total 141 reports saved\n",
      "Total 142 reports saved\n",
      "Total 143 reports saved\n",
      "Total 144 reports saved\n",
      "Total 145 reports saved\n",
      "Total 146 reports saved\n",
      "Total 147 reports saved\n",
      "Total 148 reports saved\n",
      "Total 149 reports saved\n",
      "Total 150 reports saved\n",
      "Total 151 reports saved\n",
      "Total 152 reports saved\n"
     ]
    }
   ],
   "source": [
    "print('Downloading reports...')\n",
    "reports = []\n",
    "for url in links:\n",
    "    r = requests.get(url)\n",
    "    data = r.text\n",
    "    soup = BeautifulSoup(data, \"html.parser\")\n",
    "    reports.append(soup.get_text())\n",
    "    print(f'Total {len(reports)} reports saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dic = pd.read_excel('LoughranMcDonald_MasterDictionary_2018.xlsx')\n",
    "#master_dic.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\apoor'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\apoor\\\\Downloads\\\\FINREP-master'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u'C:\\\\Users\\\\apoor\\\\Downloads\\\\FINREP-master'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Stop Words are 121\n"
     ]
    }
   ],
   "source": [
    "with open('C:\\\\Users\\\\apoor\\\\Downloads\\\\StopWords_Generic.txt','r') as f:\n",
    "    stop_words = f.read()\n",
    "\n",
    "stop_words = stop_words.split('\\n')\n",
    "print(f'Total number of Stop Words are {len(stop_words)}')\n",
    "\n",
    "#print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABOUT', 'ABOVE', 'AFTER', 'AGAIN', 'ALL', 'AM', 'AMONG', 'AN', 'AND', 'ANY', 'ARE', 'AS', 'AT', 'BE', 'BECAUSE', 'BEEN', 'BEFORE', 'BEING', 'BELOW', 'BETWEEN', 'BOTH', 'BUT', 'BY', 'CAN', 'DID', 'DO', 'DOES', 'DOING', 'DOWN', 'DURING', 'EACH', 'FEW', 'FOR', 'FROM', 'FURTHER', 'HAD', 'HAS', 'HAVE', 'HAVING', 'HE', 'HER', 'HERE', 'HERS', 'HERSELF', 'HIM', 'HIMSELF', 'HIS', 'HOW', 'IF', 'IN', 'INTO', 'IS', 'IT', 'ITS', 'ITSELF', 'JUST', 'ME', 'MORE', 'MOST', 'MY', 'MYSELF', 'NO', 'NOR', 'NOT', 'NOW', 'OF', 'OFF', 'ON', 'ONCE', 'ONLY', 'OR', 'OTHER', 'OUR', 'OURS', 'OURSELVES', 'OUT', 'OVER', 'OWN', 'SAME', 'SHE', 'SHOULD', 'SO', 'SOME', 'SUCH', 'THAN', 'THAT', 'THE', 'THEIR', 'THEIRS', 'THEM', 'THEMSELVES', 'THEN', 'THERE', 'THESE', 'THEY', 'THIS', 'THOSE', 'THROUGH', 'TO', 'TOO', 'UNDER', 'UNTIL', 'UP', 'VERY', 'WAS', 'WE', 'WERE', 'WHAT', 'WHEN', 'WHERE', 'WHICH', 'WHILE', 'WHO', 'WHOM', 'WHY', 'WITH', 'YOU', 'YOUR', 'YOURS', 'YOURSELF', 'YOURSELVES']\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dic = pd.read_excel('C:\\\\Users\\\\apoor\\\\Downloads\\\\LoughranMcDonald_MasterDictionary_2018.xlsx')\n",
    "#master_dic.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positve words in dictionary are 354\n",
      "Total negative words in dictionary are 2355\n"
     ]
    }
   ],
   "source": [
    "positive_dictionary = [x for x in master_dic[master_dic['Positive'] != 0]['Word']]\n",
    "\n",
    "negative_dictionary = [x for x in master_dic[master_dic['Negative'] != 0]['Word']]\n",
    "\n",
    "print(f\"Total positve words in dictionary are {len(positive_dictionary)}\")\n",
    "print(f\"Total negative words in dictionary are {len(negative_dictionary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\apoor'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainity = pd.read_excel('C:\\\\Users\\\\apoor\\\\Downloads\\\\uncertainty_dictionary.xlsx')\n",
    "uncertainity_words = list(uncertainity['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraining = pd.read_excel('C:\\\\Users\\\\apoor\\\\Downloads\\\\constraining_dictionary.xlsx')\n",
    "constraining_words = list(constraining['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = re.sub(r'[^A-Za-z]',' ',text.upper())\n",
    "    tokenized_words = word_tokenize(text)\n",
    "    return tokenized_words\n",
    "\n",
    "def remove_stopwords(words, stop_words):\n",
    "    return [x for x in words if x not in stop_words]\n",
    "    \n",
    "def countfunc(store, words):\n",
    "    score = 0\n",
    "    for x in words:\n",
    "        if(x in store):\n",
    "            score = score+1\n",
    "    return score\n",
    "\n",
    "def sentiment(score):\n",
    "    if(score < -0.5):\n",
    "        return 'Most Negative'\n",
    "    elif(score >= -0.5 and score < 0):\n",
    "        return 'Negative'\n",
    "    elif(score == 0):\n",
    "        return 'Neutral'\n",
    "    elif(score > 0 and score < 0.5):\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Very Positive'\n",
    "    \n",
    "\n",
    "def polarity(positive_score, negative_score):\n",
    "    return (positive_score - negative_score)/((positive_score + negative_score)+ 0.000001)\n",
    "     \n",
    "\n",
    "def subjectivity(positive_score, negative_score, num_words):\n",
    "    return (positive_score+negative_score)/(num_words+ 0.000001)\n",
    "\n",
    "def syllable_morethan2(word):\n",
    "    if(len(word) > 2 and (word[-2:] == 'es' or word[-2:] == 'ed')):\n",
    "        return False\n",
    "    \n",
    "    count =0\n",
    "    vowels = ['a','e','i','o','u']\n",
    "    for i in word:\n",
    "        if(i.lower() in vowels):\n",
    "            count = count +1\n",
    "        \n",
    "    if(count > 2):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def fog_index_cal(average_sentence_length, percentage_complexwords):\n",
    "    return 0.4*(average_sentence_length + percentage_complexwords)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = [\"Management's Discussion and Analysis\",\n",
    "            \"Quantitative and Qualitative Disclosures about Market Risk\\n\",\n",
    "            \"Risk Factors\\n\"]\n",
    "caps = [x.upper() for x in sections]\n",
    "\n",
    "caps.extend(sections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['mda','qqdmr','rf']\n",
    "var = ['positive_score',\n",
    "      'negative_score',\n",
    "      'polarity_score',\n",
    "      'average_sentence_length',\n",
    "      'percentage_of_complex_words',\n",
    "      'fog_index',\n",
    "      'complex_word_count',\n",
    "      'word_count',\n",
    "      'uncertainity_score',\n",
    "      'constraining_score',\n",
    "      'positive_word_proportion',\n",
    "      'negative_word_proportion',\n",
    "      'uncertainity_word_proportion',\n",
    "      'constraining_word_proportion',\n",
    "      'constraining_words_whole_report']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in col:\n",
    "    for v in var[:-1]:\n",
    "        df[c+'_'+v] = 0.0\n",
    "\n",
    "df[var[-1]] = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>CONAME</th>\n",
       "      <th>FYRMO</th>\n",
       "      <th>FDATE</th>\n",
       "      <th>FORM</th>\n",
       "      <th>SECFNAME</th>\n",
       "      <th>mda_positive_score</th>\n",
       "      <th>mda_negative_score</th>\n",
       "      <th>mda_polarity_score</th>\n",
       "      <th>mda_average_sentence_length</th>\n",
       "      <th>...</th>\n",
       "      <th>rf_fog_index</th>\n",
       "      <th>rf_complex_word_count</th>\n",
       "      <th>rf_word_count</th>\n",
       "      <th>rf_uncertainity_score</th>\n",
       "      <th>rf_constraining_score</th>\n",
       "      <th>rf_positive_word_proportion</th>\n",
       "      <th>rf_negative_word_proportion</th>\n",
       "      <th>rf_uncertainity_word_proportion</th>\n",
       "      <th>rf_constraining_word_proportion</th>\n",
       "      <th>constraining_words_whole_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199803</td>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>10-K405</td>\n",
       "      <td>edgar/data/3662/0000950170-98-000413.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199805</td>\n",
       "      <td>1998-05-15</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-001001.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199808</td>\n",
       "      <td>1998-08-13</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-000783.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-12</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002145.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-16</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-001203.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    CIK            CONAME   FYRMO      FDATE     FORM  \\\n",
       "0  3662  SUNBEAM CORP/FL/  199803 1998-03-06  10-K405   \n",
       "1  3662  SUNBEAM CORP/FL/  199805 1998-05-15     10-Q   \n",
       "2  3662  SUNBEAM CORP/FL/  199808 1998-08-13  NT 10-Q   \n",
       "3  3662  SUNBEAM CORP/FL/  199811 1998-11-12   10-K/A   \n",
       "4  3662  SUNBEAM CORP/FL/  199811 1998-11-16  NT 10-Q   \n",
       "\n",
       "                                   SECFNAME  mda_positive_score  \\\n",
       "0  edgar/data/3662/0000950170-98-000413.txt                 0.0   \n",
       "1  edgar/data/3662/0000950170-98-001001.txt                 0.0   \n",
       "2  edgar/data/3662/0000950172-98-000783.txt                 0.0   \n",
       "3  edgar/data/3662/0000950170-98-002145.txt                 0.0   \n",
       "4  edgar/data/3662/0000950172-98-001203.txt                 0.0   \n",
       "\n",
       "   mda_negative_score  mda_polarity_score  mda_average_sentence_length  ...  \\\n",
       "0                 0.0                 0.0                          0.0  ...   \n",
       "1                 0.0                 0.0                          0.0  ...   \n",
       "2                 0.0                 0.0                          0.0  ...   \n",
       "3                 0.0                 0.0                          0.0  ...   \n",
       "4                 0.0                 0.0                          0.0  ...   \n",
       "\n",
       "   rf_fog_index  rf_complex_word_count  rf_word_count  rf_uncertainity_score  \\\n",
       "0           0.0                    0.0            0.0                    0.0   \n",
       "1           0.0                    0.0            0.0                    0.0   \n",
       "2           0.0                    0.0            0.0                    0.0   \n",
       "3           0.0                    0.0            0.0                    0.0   \n",
       "4           0.0                    0.0            0.0                    0.0   \n",
       "\n",
       "   rf_constraining_score  rf_positive_word_proportion  \\\n",
       "0                    0.0                          0.0   \n",
       "1                    0.0                          0.0   \n",
       "2                    0.0                          0.0   \n",
       "3                    0.0                          0.0   \n",
       "4                    0.0                          0.0   \n",
       "\n",
       "   rf_negative_word_proportion  rf_uncertainity_word_proportion  \\\n",
       "0                          0.0                              0.0   \n",
       "1                          0.0                              0.0   \n",
       "2                          0.0                              0.0   \n",
       "3                          0.0                              0.0   \n",
       "4                          0.0                              0.0   \n",
       "\n",
       "   rf_constraining_word_proportion  constraining_words_whole_report  \n",
       "0                              0.0                              0.0  \n",
       "1                              0.0                              0.0  \n",
       "2                              0.0                              0.0  \n",
       "3                              0.0                              0.0  \n",
       "4                              0.0                              0.0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Management's Discussion and Analysis\": 'mda', 'Quantitative and Qualitative Disclosures about Market Risk\\n': 'qqdmr', 'Risk Factors\\n': 'rf', \"MANAGEMENT'S DISCUSSION AND ANALYSIS\": 'mda', 'QUANTITATIVE AND QUALITATIVE DISCLOSURES ABOUT MARKET RISK\\n': 'qqdmr', 'RISK FACTORS\\n': 'rf'}\n"
     ]
    }
   ],
   "source": [
    "section_map = {i:j for i,j in zip(sections, col)}\n",
    "s_map = {i.upper():j for i,j in zip(sections, col)}\n",
    "\n",
    "section_map.update(s_map)\n",
    "print(section_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th row processing\n",
      "1th row processing\n",
      "2th row processing\n",
      "3th row processing\n",
      "4th row processing\n",
      "5th row processing\n",
      "6th row processing\n",
      "7th row processing\n",
      "8th row processing\n",
      "9th row processing\n",
      "10th row processing\n",
      "11th row processing\n",
      "12th row processing\n",
      "13th row processing\n",
      "14th row processing\n",
      "15th row processing\n",
      "16th row processing\n",
      "17th row processing\n",
      "18th row processing\n",
      "19th row processing\n",
      "20th row processing\n",
      "21th row processing\n",
      "22th row processing\n",
      "23th row processing\n",
      "24th row processing\n",
      "25th row processing\n",
      "26th row processing\n",
      "27th row processing\n",
      "28th row processing\n",
      "29th row processing\n",
      "30th row processing\n",
      "31th row processing\n",
      "32th row processing\n",
      "33th row processing\n",
      "34th row processing\n",
      "35th row processing\n",
      "36th row processing\n",
      "37th row processing\n",
      "38th row processing\n",
      "39th row processing\n",
      "40th row processing\n",
      "41th row processing\n",
      "42th row processing\n",
      "43th row processing\n",
      "44th row processing\n",
      "45th row processing\n",
      "46th row processing\n",
      "47th row processing\n",
      "48th row processing\n",
      "49th row processing\n",
      "50th row processing\n",
      "51th row processing\n",
      "52th row processing\n",
      "53th row processing\n",
      "54th row processing\n",
      "55th row processing\n",
      "56th row processing\n",
      "57th row processing\n",
      "58th row processing\n",
      "59th row processing\n",
      "60th row processing\n",
      "61th row processing\n",
      "62th row processing\n",
      "63th row processing\n",
      "64th row processing\n",
      "65th row processing\n",
      "66th row processing\n",
      "67th row processing\n",
      "68th row processing\n",
      "69th row processing\n",
      "70th row processing\n",
      "71th row processing\n",
      "72th row processing\n",
      "73th row processing\n",
      "74th row processing\n",
      "75th row processing\n",
      "76th row processing\n",
      "77th row processing\n",
      "78th row processing\n",
      "79th row processing\n",
      "80th row processing\n",
      "81th row processing\n",
      "82th row processing\n",
      "83th row processing\n",
      "84th row processing\n",
      "85th row processing\n",
      "86th row processing\n",
      "87th row processing\n",
      "88th row processing\n",
      "89th row processing\n",
      "90th row processing\n",
      "91th row processing\n",
      "92th row processing\n",
      "93th row processing\n",
      "94th row processing\n",
      "95th row processing\n",
      "96th row processing\n",
      "97th row processing\n",
      "98th row processing\n",
      "99th row processing\n",
      "100th row processing\n",
      "101th row processing\n",
      "102th row processing\n",
      "103th row processing\n",
      "104th row processing\n",
      "105th row processing\n",
      "106th row processing\n",
      "107th row processing\n",
      "108th row processing\n",
      "109th row processing\n",
      "110th row processing\n",
      "111th row processing\n",
      "112th row processing\n",
      "113th row processing\n",
      "114th row processing\n",
      "115th row processing\n",
      "116th row processing\n",
      "117th row processing\n",
      "118th row processing\n",
      "119th row processing\n",
      "120th row processing\n",
      "121th row processing\n",
      "122th row processing\n",
      "123th row processing\n",
      "124th row processing\n",
      "125th row processing\n",
      "126th row processing\n",
      "127th row processing\n",
      "128th row processing\n",
      "129th row processing\n",
      "130th row processing\n",
      "131th row processing\n",
      "132th row processing\n",
      "133th row processing\n",
      "134th row processing\n",
      "135th row processing\n",
      "136th row processing\n",
      "137th row processing\n",
      "138th row processing\n",
      "139th row processing\n",
      "140th row processing\n",
      "141th row processing\n",
      "142th row processing\n",
      "143th row processing\n",
      "144th row processing\n",
      "145th row processing\n",
      "146th row processing\n",
      "147th row processing\n",
      "148th row processing\n",
      "149th row processing\n",
      "150th row processing\n",
      "151th row processing\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(reports)):\n",
    "    print(f'{i}th row processing')\n",
    "    text = re.sub('Item','ITEM',reports[i])\n",
    "    for j in caps:\n",
    "        x = re.search('ITEM\\s+[\\d]\\(*[A-Za-z]*\\)*.*\\s+\\-*\\s*'+j, text)\n",
    "        \n",
    "        if x:\n",
    "            start,end = x.span()\n",
    "            content = (text[start:]).split('ITEM')[1]\n",
    "            if ('...' not in content) and ('. . .' not in content) and len(content) > 100:\n",
    "                tokenized_words = tokenize(content)\n",
    "                #print(f'Total tokenized words are {len(tokenized_words)}')\n",
    "                words = remove_stopwords(tokenized_words, stop_words)\n",
    "                num_words = len(words)\n",
    "                #print(f'Total words after removing stop words are {len(words)}')\n",
    "                positive_score = countfunc(positive_dictionary, words)\n",
    "                negative_score = countfunc(negative_dictionary, words)\n",
    "                #print(f'Total positive score is {positive_score}')\n",
    "                #print(f'Total negative score is {negative_score}')\n",
    "                polarity_score = polarity(positive_score, negative_score)\n",
    "                #print(polarity_score)\n",
    "                subjectivity_score = subjectivity(positive_score, negative_score, num_words)\n",
    "                #print(subjectivity_score)\n",
    "                #print(sentiment(polarity_score))\n",
    "                \n",
    "                sentences = sent_tokenize(content)\n",
    "                num_sentences = len(sentences)\n",
    "                average_sentence_length = num_words/num_sentences\n",
    "                #print(average_sentence_length)\n",
    "                \n",
    "                \n",
    "                num_complexword =0\n",
    "                uncertainity_score = 0\n",
    "                constraining_score = 0\n",
    "                \n",
    "                for word in words:\n",
    "                    if(syllable_morethan2(word)):\n",
    "                        num_complexword = num_complexword+1\n",
    "                        \n",
    "                    if(word in uncertainity_words):\n",
    "                        uncertainity_score = uncertainity_score+1\n",
    "                        \n",
    "                    if(word in constraining_words):\n",
    "                        constraining_score = constraining_score+1\n",
    "                        \n",
    "                #print(num_complexword)\n",
    "                #print(uncertainity_score)\n",
    "                #print(constraining_score)\n",
    "                \n",
    "                \n",
    "                percentage_complexwords = num_complexword/num_words\n",
    "                #print(percentage_complexwords)\n",
    "                fog_index = fog_index_cal(average_sentence_length, percentage_complexwords)\n",
    "                #print(fog_index)\n",
    "                \n",
    "                positive_word_proportion = positive_score/num_words\n",
    "                negative_word_proportion = negative_score/num_words\n",
    "                uncertainity_word_proportion = uncertainity_score/num_words\n",
    "                constraining_word_proportion = constraining_score/num_words\n",
    "                \n",
    "                #print(positive_word_proportion)\n",
    "                #print(negative_word_proportion)\n",
    "                #print(uncertainity_word_proportion)\n",
    "                #print(constraining_word_proportion)\n",
    "                \n",
    "                \n",
    "                df.at[i,section_map[j]+'_positive_score'] = positive_score\n",
    "                df.at[i,section_map[j]+'_negative_score'] = negative_score\n",
    "                df.at[i,section_map[j]+'_polarity_score'] = polarity_score\n",
    "                df.at[i,section_map[j]+'_average_sentence_length'] = average_sentence_length\n",
    "                df.at[i,section_map[j]+'_percentage_of_complex_words'] = percentage_complexwords\n",
    "                df.at[i,section_map[j]+'_fog_index'] = fog_index\n",
    "                df.at[i,section_map[j]+'_complex_word_count'] = num_complexword\n",
    "                df.at[i,section_map[j]+'_word_count'] = num_words\n",
    "                df.at[i,section_map[j]+'_uncertainity_score'] = uncertainity_score\n",
    "                df.at[i,section_map[j]+'_constraining_score'] = constraining_score\n",
    "                df.at[i,section_map[j]+'_positive_word_proportion'] = positive_word_proportion\n",
    "                df.at[i,section_map[j]+'_negative_word_proportion'] = negative_word_proportion\n",
    "                df.at[i,section_map[j]+'_uncertainity_word_proportion'] = uncertainity_word_proportion\n",
    "                df.at[i,section_map[j]+'_constraining_word_proportion'] = constraining_word_proportion\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "    constraining_words_whole_report = 0\n",
    "    tokenized_report_words = tokenize(reports[i])\n",
    "    report_words = remove_stopwords(tokenized_report_words, stop_words)\n",
    "    for word in report_words:\n",
    "        if word in constraining_words:\n",
    "            constraining_words_whole_report = 1+ constraining_words_whole_report\n",
    "    #print(constraining_words_whole_report)\n",
    "    df.at[i,'constraining_words_whole_report'] = constraining_words_whole_report\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>CONAME</th>\n",
       "      <th>FYRMO</th>\n",
       "      <th>FDATE</th>\n",
       "      <th>FORM</th>\n",
       "      <th>SECFNAME</th>\n",
       "      <th>mda_positive_score</th>\n",
       "      <th>mda_negative_score</th>\n",
       "      <th>mda_polarity_score</th>\n",
       "      <th>mda_average_sentence_length</th>\n",
       "      <th>...</th>\n",
       "      <th>rf_fog_index</th>\n",
       "      <th>rf_complex_word_count</th>\n",
       "      <th>rf_word_count</th>\n",
       "      <th>rf_uncertainity_score</th>\n",
       "      <th>rf_constraining_score</th>\n",
       "      <th>rf_positive_word_proportion</th>\n",
       "      <th>rf_negative_word_proportion</th>\n",
       "      <th>rf_uncertainity_word_proportion</th>\n",
       "      <th>rf_constraining_word_proportion</th>\n",
       "      <th>constraining_words_whole_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199803</td>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>10-K405</td>\n",
       "      <td>edgar/data/3662/0000950170-98-000413.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199805</td>\n",
       "      <td>1998-05-15</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-001001.txt</td>\n",
       "      <td>11.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-0.671642</td>\n",
       "      <td>23.753425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1046.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199808</td>\n",
       "      <td>1998-08-13</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-000783.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-12</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002145.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-16</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-001203.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    CIK            CONAME   FYRMO      FDATE     FORM  \\\n",
       "0  3662  SUNBEAM CORP/FL/  199803 1998-03-06  10-K405   \n",
       "1  3662  SUNBEAM CORP/FL/  199805 1998-05-15     10-Q   \n",
       "2  3662  SUNBEAM CORP/FL/  199808 1998-08-13  NT 10-Q   \n",
       "3  3662  SUNBEAM CORP/FL/  199811 1998-11-12   10-K/A   \n",
       "4  3662  SUNBEAM CORP/FL/  199811 1998-11-16  NT 10-Q   \n",
       "\n",
       "                                   SECFNAME  mda_positive_score  \\\n",
       "0  edgar/data/3662/0000950170-98-000413.txt                 0.0   \n",
       "1  edgar/data/3662/0000950170-98-001001.txt                11.0   \n",
       "2  edgar/data/3662/0000950172-98-000783.txt                 0.0   \n",
       "3  edgar/data/3662/0000950170-98-002145.txt                 0.0   \n",
       "4  edgar/data/3662/0000950172-98-001203.txt                 0.0   \n",
       "\n",
       "   mda_negative_score  mda_polarity_score  mda_average_sentence_length  ...  \\\n",
       "0                 0.0            0.000000                     0.000000  ...   \n",
       "1                56.0           -0.671642                    23.753425  ...   \n",
       "2                 0.0            0.000000                     0.000000  ...   \n",
       "3                 0.0            0.000000                     0.000000  ...   \n",
       "4                 0.0            0.000000                     0.000000  ...   \n",
       "\n",
       "   rf_fog_index  rf_complex_word_count  rf_word_count  rf_uncertainity_score  \\\n",
       "0           0.0                    0.0            0.0                    0.0   \n",
       "1           0.0                    0.0            0.0                    0.0   \n",
       "2           0.0                    0.0            0.0                    0.0   \n",
       "3           0.0                    0.0            0.0                    0.0   \n",
       "4           0.0                    0.0            0.0                    0.0   \n",
       "\n",
       "   rf_constraining_score  rf_positive_word_proportion  \\\n",
       "0                    0.0                          0.0   \n",
       "1                    0.0                          0.0   \n",
       "2                    0.0                          0.0   \n",
       "3                    0.0                          0.0   \n",
       "4                    0.0                          0.0   \n",
       "\n",
       "   rf_negative_word_proportion  rf_uncertainity_word_proportion  \\\n",
       "0                          0.0                              0.0   \n",
       "1                          0.0                              0.0   \n",
       "2                          0.0                              0.0   \n",
       "3                          0.0                              0.0   \n",
       "4                          0.0                              0.0   \n",
       "\n",
       "   rf_constraining_word_proportion  constraining_words_whole_report  \n",
       "0                              0.0                              5.0  \n",
       "1                              0.0                           1046.0  \n",
       "2                              0.0                              5.0  \n",
       "3                              0.0                            716.0  \n",
       "4                              0.0                              4.0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved\n"
     ]
    }
   ],
   "source": [
    "df.to_excel('output.xlsx')\n",
    "\n",
    "print('File saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
